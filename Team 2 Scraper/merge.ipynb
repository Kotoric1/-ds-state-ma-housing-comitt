{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3ccfa2",
   "metadata": {},
   "source": [
    "### Merge\n",
    "Helper code used to merge output csvs throughout the scraping process for our preliminary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb8bc925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "    \n",
    "\"\"\"Our code would save the cases for each particular day and court in case of an IP failure.\n",
    "    This code was used to merge the court csvs in the case of a failure for some day.\"\"\"\n",
    "date = \"01.31.2020\"\n",
    "file_names = [\"./data/\"+court+\"_\"+date+\"-\"+date+\".csv\" for court in ['Central Housing', 'Eastern Housing', 'Metro South Housing', 'Northeast Housing', 'Southeast Housing', 'Western Housing']]\n",
    "\n",
    "out_name = \"./data/\"+date+\"-\"+date+\"2.csv\"\n",
    "with open(out_name, \"a\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(file_names):\n",
    "        try:\n",
    "            with open(file_names[i]) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                # first file:\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "                break\n",
    "        except FileNotFoundError:\n",
    "            i+=1\n",
    "        \n",
    "    \n",
    "    # now the rest:  \n",
    "    for f_name in file_names[i:]:\n",
    "        try:\n",
    "            with open(f_name) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                next(reader, None)\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "df = pd.read_csv(out_name)\n",
    "df = df.drop_duplicates(subset=\"caseNum\", ignore_index=True).drop('Unnamed: 0', axis=1)\n",
    "df.to_csv(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee6727d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This code merges the csvs for each day into one.\"\"\"\n",
    "days = [str(day) if day >= 10 else '0'+str(day) for day in range(1,32)]\n",
    "file_names = [\"./data/01.\"+day+\".2020-01.\"+day+\".2020.csv\" for day in days]\n",
    "\n",
    "out_name = \"./data/01.01.2020-01.31.2020.csv\"\n",
    "with open(out_name, \"a\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    with open(file_names[0]) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        # first file:\n",
    "        for row in reader:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # now the rest:  \n",
    "    for f_name in file_names[1:]:\n",
    "        try:\n",
    "            with open(f_name) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                next(reader, None)\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "df = pd.read_csv(out_name)\n",
    "df = df.drop_duplicates(subset=\"caseNum\", ignore_index=True).drop('Unnamed: 0', axis=1)\n",
    "df.to_csv(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da7ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"Finally, we merged the data for the two months together, and then into a full dataset.\"\"\"\n",
    "housing = pd.read_csv(\"01.01.2020-01.31.2020.csv\").append(pd.read_csv(\"01.01.2021-01.31.2021.csv\"), ignore_index=True).drop('Unnamed: 0', axis=1)\n",
    "district = pd.read_csv(\"D01.01.2020-01.31.2020.csv\").append(pd.read_csv(\"D01.01.2021-01.31.2021.csv\"), ignore_index=True).drop('Unnamed: 0', axis=1)\n",
    "full = housing.append(district, ignore_index=True)\n",
    "\n",
    "housing.to_csv(\"housing_dataset.csv\")\n",
    "district.to_csv(\"district_dataset.csv\")\n",
    "full.to_csv(\"full_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7f20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
